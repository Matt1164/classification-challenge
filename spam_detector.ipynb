{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the Data\n",
    "\n",
    "The data is located at [https://static.bc-edx.com/ai/ail-v-1-0/m13/challenge/spam-data.csv](https://static.bc-edx.com/ai/ail-v-1-0/m13/challenge/spam-data.csv)\n",
    "\n",
    "Dataset Source: [UCI Machine Learning Library](https://archive.ics.uci.edu/dataset/94/spambase)\n",
    "\n",
    "Import the data using Pandas. Display the resulting DataFrame to confirm the import was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00  ...         0.00        0.000   \n",
       "1             0.00            0.94  ...         0.00        0.132   \n",
       "2             0.64            0.25  ...         0.01        0.143   \n",
       "3             0.31            0.63  ...         0.00        0.137   \n",
       "4             0.31            0.63  ...         0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  spam  \n",
       "0                       278     1  \n",
       "1                      1028     1  \n",
       "2                      2259     1  \n",
       "3                       191     1  \n",
       "4                       191     1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "data = pd.read_csv(\"https://static.bc-edx.com/ai/ail-v-1-0/m13/challenge/spam-data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Model Performance\n",
    "\n",
    "You will be creating and comparing two models on this data: a Logistic Regression, and a Random Forests Classifier. Before you create, fit, and score the models, make a prediction as to which model you think will perform better. You do not need to be correct! \n",
    "\n",
    "Write down your prediction in the designated cells in your Jupyter Notebook, and provide justification for your educated guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Replace the text in this markdown cell with your predictions, and be sure to provide justification for your guess.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    1\n",
       " 1    1\n",
       " 2    1\n",
       " 3    1\n",
       " 4    1\n",
       " Name: spam, dtype: int64,\n",
       "    word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       " 0            0.00               0.64           0.64           0.0   \n",
       " 1            0.21               0.28           0.50           0.0   \n",
       " 2            0.06               0.00           0.71           0.0   \n",
       " 3            0.00               0.00           0.00           0.0   \n",
       " 4            0.00               0.00           0.00           0.0   \n",
       " \n",
       "    word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       " 0           0.32            0.00              0.00                0.00   \n",
       " 1           0.14            0.28              0.21                0.07   \n",
       " 2           1.23            0.19              0.19                0.12   \n",
       " 3           0.63            0.00              0.31                0.63   \n",
       " 4           0.63            0.00              0.31                0.63   \n",
       " \n",
       "    word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n",
       " 0             0.00            0.00  ...                   0.0         0.00   \n",
       " 1             0.00            0.94  ...                   0.0         0.00   \n",
       " 2             0.64            0.25  ...                   0.0         0.01   \n",
       " 3             0.31            0.63  ...                   0.0         0.00   \n",
       " 4             0.31            0.63  ...                   0.0         0.00   \n",
       " \n",
       "    char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       " 0        0.000          0.0        0.778        0.000        0.000   \n",
       " 1        0.132          0.0        0.372        0.180        0.048   \n",
       " 2        0.143          0.0        0.276        0.184        0.010   \n",
       " 3        0.137          0.0        0.137        0.000        0.000   \n",
       " 4        0.135          0.0        0.135        0.000        0.000   \n",
       " \n",
       "    capital_run_length_average  capital_run_length_longest  \\\n",
       " 0                       3.756                          61   \n",
       " 1                       5.114                         101   \n",
       " 2                       9.821                         485   \n",
       " 3                       3.537                          40   \n",
       " 4                       3.537                          40   \n",
       " \n",
       "    capital_run_length_total  \n",
       " 0                       278  \n",
       " 1                      1028  \n",
       " 2                      2259  \n",
       " 3                       191  \n",
       " 4                       191  \n",
       " \n",
       " [5 rows x 57 columns])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the labels set `y` and features DataFrame `X`\n",
    "# Create labels (y) and features (X)\n",
    "y = data['spam']  # Assuming 'spam' is the column containing the labels (0 for not spam, 1 for spam)\n",
    "X = data.drop('spam', axis=1)  # Exclude the 'spam' column to get the feature set\n",
    "\n",
    "# Display the first few rows of the labels and features\n",
    "y.head(), X.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam\n",
       "0    2788\n",
       "1    1813\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance of the labels variable (`y`) by using the `value_counts` function.\n",
    "# Check the balance of the labels variable (y)\n",
    "y.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (3680, 57) (3680,)\n",
      "Testing set shape: (921, 57) (921,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Display the shapes of the resulting sets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "# Print the shape of the training and testing sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `StandardScaler` to scale the features data. Remember that only `X_train` and `X_test` DataFrames should be scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create an instance of StandardScaler\n",
    "scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Standard Scaler with the training data\n",
    "X_train_scaled = scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training data\n",
    "# Fit the Standard Scaler with the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the testing features using the fitted scaler from the training data\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.35849294, -0.1663156 , -0.56145245, -0.04622283, -0.46213226,\n",
       "         -0.34826528, -0.28974258, -0.25433765, -0.32332618, -0.37163401,\n",
       "         -0.29468554, -0.62650109, -0.31339295, -0.17532912, -0.19447397,\n",
       "         -0.29414289, -0.31752206, -0.35579466,  0.13679517, -0.16618766,\n",
       "         -0.67441325, -0.12561726, -0.29347046, -0.215155  , -0.32371654,\n",
       "         -0.29991686, -0.22988673, -0.22211804, -0.16692576, -0.21817596,\n",
       "         -0.1695615 , -0.14085718, -0.17082404, -0.14304829, -0.18630409,\n",
       "         -0.23399564, -0.32328961, -0.06090721, -0.18036846, -0.18204882,\n",
       "         -0.12120056, -0.17268519, -0.20493605, -0.14140736, -0.30532057,\n",
       "         -0.19618137, -0.07194518, -0.1076204 , -0.156207  , -0.48491863,\n",
       "         -0.15134534, -0.32037559, -0.31155305,  0.69767005, -0.108199  ,\n",
       "         -0.21450276, -0.43523962],\n",
       "        [-0.08676893, -0.03497293, -0.22384706, -0.04622283,  0.74237706,\n",
       "         -0.06285915, -0.28974258,  0.38019668, -0.32332618, -0.37163401,\n",
       "         -0.29468554,  3.24704251,  0.24937939, -0.17532912, -0.19447397,\n",
       "         -0.20133663, -0.31752206, -0.35579466, -0.93262282, -0.16618766,\n",
       "         -0.67441325, -0.12561726, -0.29347046, -0.215155  ,  1.25093513,\n",
       "         -0.29991686, -0.22988673, -0.22211804, -0.16692576, -0.21817596,\n",
       "         -0.1695615 , -0.14085718, -0.17082404, -0.14304829, -0.18630409,\n",
       "          0.61800409, -0.1345897 , -0.06090721, -0.18036846, -0.18204882,\n",
       "         -0.12120056, -0.06776615,  0.14118966, -0.14140736, -0.30532057,\n",
       "         -0.19618137, -0.07194518, -0.1076204 , -0.07030995, -0.32497446,\n",
       "         -0.15134534, -0.32037559, -0.21639454, -0.10482275, -0.09401246,\n",
       "          0.0181882 ,  0.26082846],\n",
       "        [-0.35849294, -0.1663156 ,  3.11248864, -0.04622283, -0.46213226,\n",
       "         -0.34826528, -0.28974258, -0.25433765, -0.32332618,  2.41173712,\n",
       "         -0.29468554,  1.48737964,  5.81089431, -0.17532912, -0.19447397,\n",
       "         -0.29414289, -0.31752206, -0.35579466,  2.15866357, -0.16618766,\n",
       "         -0.67441325, -0.12561726, -0.29347046, -0.215155  , -0.32371654,\n",
       "         -0.29991686, -0.22988673, -0.22211804, -0.16692576, -0.21817596,\n",
       "         -0.1695615 , -0.14085718, -0.17082404, -0.14304829, -0.18630409,\n",
       "         -0.23399564, -0.32328961, -0.06090721, -0.18036846, -0.18204882,\n",
       "         -0.12120056, -0.17268519, -0.20493605, -0.14140736, -0.30532057,\n",
       "         -0.19618137, -0.07194518, -0.1076204 , -0.156207  , -0.48491863,\n",
       "         -0.15134534,  0.46355376, -0.31155305, -0.10482275, -0.13164114,\n",
       "         -0.23389368, -0.4540986 ],\n",
       "        [-0.35849294, -0.1663156 , -0.56145245, -0.04622283, -0.46213226,\n",
       "         -0.34826528, -0.28974258, -0.25433765, -0.32332618, -0.37163401,\n",
       "         -0.29468554, -0.62650109, -0.31339295, -0.17532912, -0.19447397,\n",
       "         -0.29414289, -0.31752206, -0.35579466, -0.93262282, -0.16618766,\n",
       "         -0.67441325, -0.12561726, -0.29347046, -0.215155  , -0.32371654,\n",
       "         -0.29991686, -0.22988673, -0.22211804, -0.16692576, -0.21817596,\n",
       "         -0.1695615 , -0.14085718, -0.17082404, -0.14304829, -0.18630409,\n",
       "         -0.23399564, -0.32328961, -0.06090721, -0.18036846, -0.18204882,\n",
       "         -0.12120056, -0.17268519, -0.20493605, -0.14140736,  4.05790048,\n",
       "         -0.19618137, -0.07194518, -0.1076204 , -0.156207  , -0.48491863,\n",
       "         -0.15134534, -0.32037559, -0.31155305, -0.10482275, -0.16102464,\n",
       "         -0.25328459, -0.47295759],\n",
       "        [-0.35849294, -0.1663156 , -0.56145245, -0.04622283, -0.46213226,\n",
       "         -0.34826528, -0.28974258,  0.69746385, -0.32332618, -0.37163401,\n",
       "         -0.29468554, -0.18087218, -0.31339295, -0.17532912, -0.19447397,\n",
       "         -0.29414289, -0.31752206, -0.35579466, -0.93262282, -0.16618766,\n",
       "         -0.67441325, -0.12561726, -0.29347046, -0.215155  , -0.09456947,\n",
       "         -0.29991686, -0.22988673, -0.22211804,  0.49906959,  0.61964213,\n",
       "         -0.1695615 , -0.14085718,  0.53560632, -0.14304829, -0.18630409,\n",
       "          0.71537549,  0.59662245, -0.06090721, -0.18036846, -0.18204882,\n",
       "         -0.12120056, -0.17268519, -0.20493605, -0.14140736, -0.30532057,\n",
       "         -0.19618137, -0.07194518, -0.1076204 , -0.156207  , -0.31454332,\n",
       "         -0.15134534, -0.32037559, -0.31155305, -0.10482275, -0.12060716,\n",
       "         -0.07391864, -0.274081  ]]),\n",
       " array([[-3.58492944e-01, -1.66315596e-01, -5.61452455e-01,\n",
       "         -4.62228283e-02,  1.05856076e+00, -3.48265283e-01,\n",
       "         -2.89742575e-01, -2.54337647e-01, -3.23326184e-01,\n",
       "         -3.71634012e-01, -2.94685540e-01, -6.26501090e-01,\n",
       "         -3.13392949e-01, -1.75329120e-01, -1.94473966e-01,\n",
       "         -2.94142886e-01, -3.17522061e-01, -3.55794659e-01,\n",
       "         -9.32622820e-01, -1.66187659e-01, -6.74413249e-01,\n",
       "         -1.25617263e-01, -2.93470458e-01, -2.15154996e-01,\n",
       "         -3.23716540e-01, -2.99916864e-01, -2.29886734e-01,\n",
       "         -2.22118040e-01, -1.66925758e-01, -2.18175957e-01,\n",
       "         -1.69561496e-01, -1.40857182e-01, -1.70824036e-01,\n",
       "         -1.43048289e-01, -1.86304092e-01, -2.33995642e-01,\n",
       "          1.15883922e+01, -6.09072097e-02, -1.80368457e-01,\n",
       "         -1.82048815e-01, -1.21200562e-01, -1.72685189e-01,\n",
       "         -2.04936050e-01, -1.41407365e-01, -3.05320567e-01,\n",
       "         -1.96181372e-01, -7.19451800e-02, -1.07620404e-01,\n",
       "         -1.56207004e-01, -1.78938484e-01, -1.51345343e-01,\n",
       "         -3.20375589e-01,  5.25316795e-02, -1.04822754e-01,\n",
       "          7.00825032e-02, -9.81572802e-02, -1.18065740e-01],\n",
       "        [-3.58492944e-01, -1.66315596e-01, -5.61452455e-01,\n",
       "         -4.62228283e-02, -4.62132258e-01, -3.48265283e-01,\n",
       "         -2.89742575e-01, -2.54337647e-01, -3.23326184e-01,\n",
       "         -3.71634012e-01, -2.94685540e-01, -6.26501090e-01,\n",
       "         -3.13392949e-01,  6.12646173e+00, -1.94473966e-01,\n",
       "         -2.94142886e-01, -3.17522061e-01, -3.55794659e-01,\n",
       "         -9.32622820e-01, -1.66187659e-01, -6.74413249e-01,\n",
       "         -1.25617263e-01, -2.93470458e-01, -2.15154996e-01,\n",
       "         -3.23716540e-01, -2.99916864e-01, -2.29886734e-01,\n",
       "          2.27598615e+00, -1.66925758e-01, -2.18175957e-01,\n",
       "         -1.69561496e-01, -1.40857182e-01, -1.70824036e-01,\n",
       "         -1.43048289e-01, -1.86304092e-01, -2.33995642e-01,\n",
       "         -3.23289608e-01, -6.09072097e-02, -1.80368457e-01,\n",
       "         -1.82048815e-01, -1.21200562e-01, -1.72685189e-01,\n",
       "         -2.04936050e-01, -1.41407365e-01, -3.05320567e-01,\n",
       "          2.80004322e+00, -7.19451800e-02, -1.07620404e-01,\n",
       "          2.09789150e-01,  1.56306214e+00, -1.51345343e-01,\n",
       "         -3.20375589e-01, -3.11553052e-01, -1.04822754e-01,\n",
       "         -1.18828795e-01, -1.51482293e-01, -3.28943507e-01],\n",
       "        [-3.58492944e-01,  2.43164494e-01, -5.61452455e-01,\n",
       "         -4.62228283e-02,  1.13384259e+00, -3.48265283e-01,\n",
       "          3.94131390e+00, -2.54337647e-01, -3.23326184e-01,\n",
       "          4.25764203e-01, -2.94685540e-01, -6.26501090e-01,\n",
       "         -3.13392949e-01, -1.75329120e-01,  1.92832671e+00,\n",
       "         -2.94142886e-01, -3.17522061e-01,  6.84457635e-01,\n",
       "          2.53762767e-01, -1.66187659e-01, -2.40831070e-01,\n",
       "         -1.25617263e-01, -2.93470458e-01, -2.15154996e-01,\n",
       "         -3.23716540e-01, -2.99916864e-01, -2.29886734e-01,\n",
       "         -2.22118040e-01, -1.66925758e-01, -2.18175957e-01,\n",
       "         -1.69561496e-01, -1.40857182e-01, -1.70824036e-01,\n",
       "         -1.43048289e-01, -1.86304092e-01, -2.33995642e-01,\n",
       "         -3.23289608e-01, -6.09072097e-02, -1.80368457e-01,\n",
       "         -1.82048815e-01, -1.21200562e-01, -1.72685189e-01,\n",
       "         -2.04936050e-01, -1.41407365e-01,  2.27515183e-01,\n",
       "         -1.96181372e-01, -7.19451800e-02, -1.07620404e-01,\n",
       "         -1.56207004e-01,  3.46095636e-01,  5.09371521e-01,\n",
       "         -1.40253093e-01, -3.11553052e-01, -1.04822754e-01,\n",
       "         -1.73405044e-02, -1.08981678e-02, -2.75795452e-01],\n",
       "        [-3.58492944e-01, -1.66315596e-01, -1.04692211e-01,\n",
       "         -4.62228283e-02,  9.23053460e-01, -3.48265283e-01,\n",
       "         -2.89742575e-01, -2.54337647e-01,  4.73248643e-01,\n",
       "         -3.71634012e-01, -2.94685540e-01,  4.24726082e-01,\n",
       "         -3.13392949e-01,  2.65279165e+00, -1.94473966e-01,\n",
       "         -2.94142886e-01,  1.87657872e-01, -3.55794659e-01,\n",
       "         -9.32622820e-01, -1.66187659e-01, -4.86254945e-01,\n",
       "         -1.25617263e-01, -2.93470458e-01, -2.15154996e-01,\n",
       "         -1.88578524e-01, -2.99916864e-01, -2.29886734e-01,\n",
       "          2.00355463e-01, -1.66925758e-01, -2.18175957e-01,\n",
       "          4.51562238e-01, -1.40857182e-01, -1.70824036e-01,\n",
       "         -1.43048289e-01,  2.28696523e-01, -2.33995642e-01,\n",
       "          2.19222633e-01, -6.09072097e-02, -1.80368457e-01,\n",
       "         -1.82048815e-01, -1.21200562e-01,  1.03388374e+00,\n",
       "         -2.04936050e-01, -1.41407365e-01, -3.05320567e-01,\n",
       "         -1.96181372e-01, -7.19451800e-02, -1.07620404e-01,\n",
       "         -1.56207004e-01, -3.29025035e-02,  6.61057768e-02,\n",
       "         -2.90921596e-01, -3.11553052e-01, -4.99153510e-02,\n",
       "         -1.11634484e-01, -1.46634565e-01,  3.36264409e-01],\n",
       "        [-3.58492944e-01, -1.66315596e-01, -5.61452455e-01,\n",
       "         -4.62228283e-02, -4.62132258e-01, -3.48265283e-01,\n",
       "         -2.89742575e-01, -2.54337647e-01, -3.23326184e-01,\n",
       "         -3.71634012e-01, -2.94685540e-01, -6.26501090e-01,\n",
       "         -3.13392949e-01, -1.75329120e-01, -1.94473966e-01,\n",
       "         -2.94142886e-01, -3.17522061e-01, -3.55794659e-01,\n",
       "          2.25913340e-01, -1.66187659e-01, -6.74413249e-01,\n",
       "         -1.25617263e-01, -2.93470458e-01, -2.15154996e-01,\n",
       "         -3.23716540e-01, -2.99916864e-01, -2.29886734e-01,\n",
       "         -2.22118040e-01, -1.66925758e-01, -2.18175957e-01,\n",
       "         -1.69561496e-01, -1.40857182e-01, -1.70824036e-01,\n",
       "         -1.43048289e-01, -1.86304092e-01, -2.33995642e-01,\n",
       "         -3.23289608e-01, -6.09072097e-02, -1.80368457e-01,\n",
       "         -1.82048815e-01, -1.21200562e-01, -1.72685189e-01,\n",
       "         -2.04936050e-01, -1.41407365e-01, -3.05320567e-01,\n",
       "         -1.96181372e-01, -7.19451800e-02, -1.07620404e-01,\n",
       "         -1.56207004e-01, -4.84918633e-01, -1.51345343e-01,\n",
       "         -3.20375589e-01, -3.11553052e-01, -1.04822754e-01,\n",
       "         -1.43725962e-01, -2.38741406e-01, -4.69528685e-01]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the scaled features to check\n",
    "X_train_scaled[:5], X_test_scaled[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Fit a Logistic Regression Model\n",
    "\n",
    "Create a Logistic Regression model, fit it to the training data, make predictions with the testing data, and print the model's accuracy score. You may choose any starting settings you like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Accuracy: 0.9273\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic Regression model and print the model score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Create a Logistic Regression model\n",
    "logistic_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fit the model to the scaled training data\n",
    "logistic_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_logistic = logistic_model.predict(X_test_scaled)\n",
    "\n",
    "# Print the accuracy score of the Logistic Regression model\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "print(f\"Logistic Regression Model Accuracy: {accuracy_logistic:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual  Predicted_Logistic\n",
      "1351       1                   0\n",
      "1687       1                   0\n",
      "1297       1                   1\n",
      "2101       0                   0\n",
      "3920       0                   0\n"
     ]
    }
   ],
   "source": [
    "# Make and save testing predictions with the saved logistic regression model using the test data\n",
    "\n",
    "# Review the predictions\n",
    "# Make predictions on the test data using the logistic regression model\n",
    "test_predictions_logistic = logistic_model.predict(X_test_scaled)\n",
    "\n",
    "# Save the predictions to a DataFrame or a CSV file if needed\n",
    "# Assuming you have a DataFrame for your test data, you can create a new DataFrame for predictions\n",
    "predictions_df = pd.DataFrame({'Actual': y_test, 'Predicted_Logistic': test_predictions_logistic})\n",
    "\n",
    "# Display the predictions DataFrame\n",
    "print(predictions_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data Accuracy Score: 0.927253\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy score by evaluating `y_test` vs. `testing_predictions`.\n",
    "# Calculate the accuracy score by evaluating y_test vs. testing_predictions_logistic\n",
    "accuracy_testing = accuracy_score(y_test, predictions_df['Predicted_Logistic'])\n",
    "\n",
    "# Print the accuracy score\n",
    "print(f\"Testing Data Accuracy Score: {accuracy_testing:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Fit a Random Forest Classifier Model\n",
    "\n",
    "Create a Random Forest Classifier model, fit it to the training data, make predictions with the testing data, and print the model's accuracy score. You may choose any starting settings you like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Model Accuracy: 0.9587405\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Create a Random Forest Classifier model\n",
    "random_forest_model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Fit the model to the scaled training data\n",
    "random_forest_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_rf = random_forest_model.predict(X_test_scaled)\n",
    "\n",
    "# Print the accuracy score of the Random Forest Classifier model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Classifier Model Accuracy: {accuracy_rf:.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual  Predicted_Logistic\n",
      "1351       1                   0\n",
      "1687       1                   0\n",
      "1297       1                   1\n",
      "2101       0                   0\n",
      "3920       0                   0\n"
     ]
    }
   ],
   "source": [
    "# Make and save testing predictions with the saved logistic regression model using the test data\n",
    "\n",
    "\n",
    "# Review the predictions\n",
    "# Make predictions on the test data using the logistic regression model\n",
    "test_predictions_logistic = logistic_model.predict(X_test_scaled)\n",
    "\n",
    "# Save the predictions to a DataFrame\n",
    "predictions_logistic_df = pd.DataFrame({'Actual': y_test, 'Predicted_Logistic': test_predictions_logistic})\n",
    "\n",
    "# Display the predictions DataFrame\n",
    "print(predictions_logistic_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Model Accuracy: 0.9587405\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy score by evaluating `y_test` vs. `testing_predictions`.\n",
    "# Print the accuracy score of the Random Forest Classifier model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Classifier Model Accuracy: {accuracy_rf:.7f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Models\n",
    "\n",
    "Which model performed better? How does that compare to your prediction? Write down your results and thoughts in the following markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Replace the text in this markdown cell with your answers to these questions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Accuracy: 0.9273\n",
      "Random Forest Classifier Model Accuracy: 0.9587\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data using the Random Forest Classifier model\n",
    "test_predictions_rf = random_forest_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the accuracy score for Random Forest Classifier model\n",
    "accuracy_rf = accuracy_score(y_test, test_predictions_rf)\n",
    "\n",
    "# Print the accuracy score for both models\n",
    "print(f\"Logistic Regression Model Accuracy: {accuracy_logistic:.4f}\")\n",
    "print(f\"Random Forest Classifier Model Accuracy: {accuracy_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models were evaluated as follows:\n",
    "Logistic Regression Model Accuracy: 92.73%\n",
    "Random Forest Classifier Model Accuracy: 95.87%\n",
    "The Random Forest Classifier outperformed the Logistic Regression model in terms of accuracy, achieving a higher accuracy score. This result aligns with the common expectation that Random Forests can be more effective, especially when dealing with complex or non-linear relationships in the data.\n",
    "\n",
    "My prediction that the Random Forest model would perform better was accurate, reflecting the versatility and robustness of Random Forests in handling a variety of datasets. It's crucial to assess different models to choose the one that best suits the characteristics of the data at hand."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
